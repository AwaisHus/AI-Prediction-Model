{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "import time #Recording execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time of entire program\n",
    "programstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for null values to remove inconsistencies\n",
    "sdf = pd.read_excel('Solar_Flares_Dataset.xlsx')\n",
    "sdf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Unncessecary Extension names\n",
    "sdf.rename(columns = \n",
    "           {'\\xa0Activity':'Activity', 'Evolution\\xa0':'Evolution', \n",
    "            'Previous 24 hour flare activity code\\xa0': 'Previous 24 hour flare activity code', \n",
    "            '. Area of the largest spot\\xa0':'Area of the largest spot',\n",
    "            'M-class flares\\xa0':'M-class flares'},\n",
    "            inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing String Values to Int values for first 3 columns\n",
    "\n",
    "sdf['modified Zurich class'].replace(['A'],['1.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['B'],['2.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['C'],['3.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['D'],['4.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['E'],['5.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['F'],['6.0'],inplace=True)\n",
    "sdf['modified Zurich class'].replace(['H'],['7.0'],inplace=True)\n",
    "\n",
    "\n",
    "sdf['largest spot size'].replace(['X'],['1.0'],inplace=True)\n",
    "sdf['largest spot size'].replace(['R'],['2.0'],inplace=True)\n",
    "sdf['largest spot size'].replace(['S'],['3.0'],inplace=True)\n",
    "sdf['largest spot size'].replace(['A'],['4.0'],inplace=True)\n",
    "sdf['largest spot size'].replace(['H'],['5.0'],inplace=True)\n",
    "sdf['largest spot size'].replace(['K'],['6.0'],inplace=True)\n",
    "\n",
    "\n",
    "sdf['spot distribution'].replace(['X'],['1.0'],inplace=True)\n",
    "sdf['spot distribution'].replace(['O'],['2.0'],inplace=True)\n",
    "sdf['spot distribution'].replace(['I'],['3.0'],inplace=True)\n",
    "sdf['spot distribution'].replace(['C'],['4.0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf.drop(index=sdf[sdf['X-class flares'] == 0].index, inplace=True) #Discards 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Values of our result class\n",
    "print(sdf['C-Class Flares'].value_counts())\n",
    "print(sdf['M-class flares'].value_counts())\n",
    "print(sdf['X-class flares'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Separating the data and labels\n",
    "#X stores attributes (excluding outcome)\n",
    "#Y stores result column\n",
    "X = sdf.drop(columns = ['C-Class Flares', 'X-class flares','M-class flares'], axis=1)\n",
    "y = sdf['C-Class Flares']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardising the Data (Coverting DF Attributes to Lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing training execution time\n",
    "trainstart = time.time()\n",
    "\n",
    "# Containing the standard scaler method in a variable\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data we are going to be using to train the model\n",
    "# Transforming the data to a list\n",
    "scaler.fit(X) \n",
    "standardized_data = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the standardized data\n",
    "standardized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will represent the data that feeds into the AI\n",
    "# y represents the model, the predictor based on the information provided\n",
    "\n",
    "X = standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying X and Y\n",
    "\n",
    "print(X)\n",
    "print('')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Storing a train and test variable for both X and y (4 variables)\n",
    "# stratify=y makes a split, so the sample of values produced will be the same (for consistent results)\n",
    "# random_state=42 for consistent sample values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train, columns = \n",
    "             ['modified Zurich class',\n",
    "                 'largest spot size',\n",
    "                 'spot distribution',\n",
    "                 'Activity',\n",
    "                 'Evolution',\n",
    "                 'Previous 24 hour flare activity code',\n",
    "                 'Historically-complex',\n",
    "                 \"Did region become historically complex on this pass across the sun's disk\",\n",
    "                 'Area',\n",
    "                 'Area of the largest spot',\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train, columns = ['C-Class Flares'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape = The entire dataset\n",
    "# X_train.shape = how much data going to be used for training\n",
    "# X_test.shape = how much data going to be used for testing\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a linear kernel with SVC function\n",
    "# Generates a linear model\n",
    "classifier = svm.SVC(kernel='linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SVM by fitting training variables\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train time recorded\n",
    "trainend = time.time()\n",
    "print(\"Training execution time:\", trainend - trainstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing execution of test time\n",
    "teststart = time.time()\n",
    "\n",
    "# Prediction score on the training data\n",
    "# A prediction will be made for X_train, storing it in a training prediction variable (X_train_prediction)\n",
    "# The y_train label represents how the variable can translate its own prediction based on x_train\n",
    "\n",
    "X_train_prediction = classifier.predict(X_train)\n",
    "training_accuracy = accuracy_score(X_train_prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prediction = classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(X_test_prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of training data: ', training_accuracy)\n",
    "print('Accuracy score of testing data: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testend = time.time()\n",
    "print(\"Testing execution time:\", testend - teststart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Confusion Matrix Graph - Heat Map Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting2(y_true, y_pred):\n",
    "    labels = unique_labels(y_test)\n",
    "    column = [f'Predicted {label}' for label in labels]\n",
    "    indices = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), columns=column, index=indices)\n",
    "    \n",
    "    return sns.heatmap(table, annot = True, fmt='d', cmap='cividis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting2(y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, X_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Solar Flares from Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the data of a patient within input data:\n",
    "# input_data order = \n",
    "    #           1. 'modified Zurich class',\n",
    "    #           2. 'largest spot size',\n",
    "    #           3. 'spot distribution',\n",
    "    #           4. 'Activity',\n",
    "    #           5. 'Evolution',\n",
    "    #           6. 'Previous 24 hour flare activity code',\n",
    "    #           7. 'Historically-complex',\n",
    "    #           8. 'Did region become historically complex on this pass across the sun's disk',\n",
    "    #           9. 'Area',\n",
    "    #           10.'Area of the largest spot\n",
    "    \n",
    "    \n",
    "input_data = (7.0,4.0,1.0,1,3,1,1,1,1,1)\n",
    "\n",
    "# Changing input_data to a numpy array\n",
    "numpy_array_input_data = np.asarray(input_data)\n",
    "\n",
    "# Reshape array for one instance, otherwise the model expects 768 instances (the shape of the base dataframe)\n",
    "reshaped_input_data = numpy_array_input_data.reshape(1, -1)\n",
    "\n",
    "# Standardize the input data\n",
    "std_data = scaler.transform(reshaped_input_data)\n",
    "print(std_data)\n",
    "\n",
    "prediction = classifier.predict(std_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Outcome 0 = No solar flare, else there exists a solar flare.\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('There are no solar flares')\n",
    "else:\n",
    "    print('There is a solar flare present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of training data: ', training_accuracy)\n",
    "print('Accuracy score of testing data: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programend = time.time()\n",
    "print(\"Program Execution Time:\", programend - programstart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
